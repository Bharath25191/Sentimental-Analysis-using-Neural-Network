{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis Part 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Sentiments through Recurring Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Name:      </b> Bharathvaj Devarajan<br>\n",
    "<b> Student No.</b> 16212388<br>\n",
    "<b> Module     </b> CA684 - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Aim</b> The second part of this project is to use Deep Learning to do Sentimental Analysis and predict the sentiment of a review based on the summary text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Import Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Pandas, numpy and other helpful libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "# Scikit learn libraries for Preprocessing,evaluating, Count Vectorization and train test split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Tensorflow Learn library for training Recurrent Neural network to do Sentimental Analysis\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to establish a database connection and read the data to a panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect('/root/amazon_db.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Score is scaled between 1 to 5 , the scores with 3 represent neutral sentiments,so those reviews are omitted \n",
    "from this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "amazon_df = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "amazon_df = amazon_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "0                       1      5  1303862400  Good Quality Dog Food   \n",
       "\n",
       "                                                Text  \n",
       "0  I have bought several of the Vitality canned d...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Text Preprocessing</b>\n",
    "\n",
    "The Review scores are converted to sentiments for NLP by doing a simple transformation by setting score > 3 as positive and rest as negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def analyze(x):\n",
    "    if x >3:\n",
    "        return \"Positive\"\n",
    "    return \"Negative\"\n",
    "\n",
    "amazon_df[\"Sentiment\"] = amazon_df[\"Score\"].map(analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Check the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Sentiment = amazon_df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A look at the summary of the Product Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Summary = amazon_df[\"Summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We actually want to work on the training and testing datasets, before cleaning we will split the data into training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "X_train,X_test,y_train,y_test = train_test_split(Summary,Sentiment,test_size = 0.2,random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Good Quality Dog Food'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#  Sentimental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now The Vectors are generated by using the Count Vectorizer library, We use unigram for our predictions and also\n",
    "set regex to include only words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), token_pattern=r'\\b\\w{1,}\\b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the training data and setting the vocabulary for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vect.fit(X_train)\n",
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to preprocess the data and convert them to ID's by stripping, splittingand lowering the case of the words that are in the vocabulary <br>\n",
    "This is essential as the padding sequences and embedding only works with int data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def word_to_id(X):\n",
    "    return X.apply( lambda x: [vocab[w] for w in [w.lower().strip() for w in x.split()] if w in vocab] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the function to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train_id = word_to_id(X_train)\n",
    "X_test_id  = word_to_id(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376694                                              [20912]\n",
       "471359                                              [23951]\n",
       "177455                                        [17223, 9521]\n",
       "435725    [4133, 28991, 4106, 9578, 11202, 10998, 26272,...\n",
       "76178                                                [5478]\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Create the Pad Sequence</b> <br>\n",
    "Here the Inputs are converted to 2D array of uniform length (specified by the max length argument), the sequence is \n",
    "padded with the value (0 in this case) if it is shorter than maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train_padseqs = pad_sequences(X_train_id,maxlen=20, value=0)\n",
    "X_test_padseqs  = pad_sequences(X_test_id,maxlen=20, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420651, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padseqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert and map the output values as categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    x = x.map(lambda x: 1 if x =='Positive' else 0)\n",
    "    x = to_categorical(x,nb_classes=2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_nn = convert(y_train)\n",
    "y_test_nn =  convert(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "vector size and vocab size are calculated as they are needed to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vector_size = X_train_padseqs.shape[1]\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Creating the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Input Layer</b><br>\n",
    "The First element is the batch size which is set to none and the second element is the shape of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.input_data([None,vector_size]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Embedding Layer</b><br>\n",
    "The second layer is the embedding Layer in which we pass the input node and the row and column dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.embedding(net, input_dim=vocab_size, output_dim=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>LSTM Layer</b><br>\n",
    "The third layer is the LSTM (Long Short Term Memory) layer<br>\n",
    "The core of the model consists of an LSTM cell that processes one word at a time and computes probabilities of the possible values for the next word in the sentence. The memory state of the network is initialized with a vector of zeros and gets updated after reading each word. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.lstm(net,128,dropout=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Fully Connected </b><br>\n",
    "The fourth layer is fully connected which ensures all nodes are connected to each other.\n",
    "We also specify the activation function and the number of classes in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.fully_connected(net, 2, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Regression Layer</b><br>\n",
    "The fifth layer is the regression layer, here we specify the optimizer function, learning rate and the loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.regression(net, \n",
    "                         optimizer='adam',  \n",
    "                         learning_rate=0.0001,\n",
    "                         loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Initializing the model</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = tflearn.DNN(net, tensorboard_verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Training the model </b><br>\n",
    "I have only specified the number of epochs to 2 because of low Compute power, I am confident that an epoch of 100 \n",
    "will return amazing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 26291  | total loss: \u001b[1m\u001b[32m0.16187\u001b[0m\u001b[0m | time: 1467.102s\n",
      "| Adam | epoch: 002 | loss: 0.16187 - acc: 0.9441 -- iter: 420640/420651\n",
      "Training Step: 26292  | total loss: \u001b[1m\u001b[32m0.16346\u001b[0m\u001b[0m | time: 1513.539s\n",
      "| Adam | epoch: 002 | loss: 0.16346 - acc: 0.9435 | val_loss: 0.21143 - val_acc: 0.9192 -- iter: 420651/420651\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_padseqs,y_train_nn, validation_set=(X_test_padseqs,y_test_nn), show_metric=True, batch_size=32, n_epoch=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to avoid retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/root/model.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save('/root/model.tfl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load('/root/model.tfl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Model Evaluation</b><br>\n",
    "Argument max function, calculates the probabilities of both the cases for a particular input and returns the\n",
    "input which has the greater probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_classes = [np.argmax(i) for i in model.predict(X_test_padseqs)]\n",
    "true_classes = [np.argmax(i) for i in y_test_nn]\n",
    "\n",
    "print('Model Accuracy: %0.3f\\n'% metrics.accuracy_score(true_classes, pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Label Encoding</b><br> to do inverse transform and see the actual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_labels = list(y_train.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive', 'Negative']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark chocolate, granola -- nice combination\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "easy chili\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Best Decaf available in T-disc so far\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "crunchy good\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Best \"Pod\" coffee\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "The Best Snack I've Ever Had\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "cinnamon discs sugar free candy\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Cat Treats\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Great if you're watching sugar or carbs!\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "disappointed\n",
      "('Predicted class:', 'Negative')\n",
      "('Actual class:', 'Negative')\n",
      "\n",
      "great cookie\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Very not awesome.\n",
      "('Predicted class:', 'Negative')\n",
      "('Actual class:', 'Negative')\n",
      "\n",
      "celestial seasons caffeine free tea\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Great Variety\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Great snack\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Bring Back the Old Recipe!\n",
      "('Predicted class:', 'Negative')\n",
      "('Actual class:', 'Negative')\n",
      "\n",
      "Tasty!\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Yummy and Crunchy\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "18 month old LOVES these\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "My Dogs Love 'Em!\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Gets me to lunch time\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Just as expected\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Anita\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "The best chocolate chai!\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Really seem to help\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Wrong product sent\n",
      "('Predicted class:', 'Negative')\n",
      "('Actual class:', 'Negative')\n",
      "\n",
      "very good oatmeal\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Great\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Puppy Crack!\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n",
      "Quickie Tea Review\n",
      "('Predicted class:', 'Positive')\n",
      "('Actual class:', 'Positive')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    pred_class = np.argmax(model.predict([X_test_padseqs[i]]))\n",
    "    true_class = np.argmax(y_test_nn[i])\n",
    "    \n",
    "    print(X_test.values[i])\n",
    "    print('Predicted class:',le.inverse_transform(pred_class))\n",
    "    print('Actual class:', le.inverse_transform(true_class))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
